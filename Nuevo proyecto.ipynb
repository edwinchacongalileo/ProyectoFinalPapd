{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class AnalizadorDatos:\n",
    "    \"\"\"\n",
    "    Clase para el análisis de datos de un archivo .npy.\n",
    "    Permite cargar los datos, dividirlos en entrenamiento y validación,\n",
    "    calcular estadísticas descriptivas y generar histogramas con métricas.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ruta_archivo):\n",
    "        \"\"\"\n",
    "        Inicializa el analizador cargando los datos desde un archivo .npy.\n",
    "\n",
    "        Parámetros:\n",
    "        ruta_archivo (str): Ruta del archivo .npy con los datos.\n",
    "        \"\"\"\n",
    "        self.ruta_archivo = ruta_archivo\n",
    "        self.datos = None\n",
    "        self.df = None\n",
    "        self.entrenamiento = None\n",
    "        self.validacion = None\n",
    "        self.nombres_columnas = [\"SalePrice\", \"OverallQual\", \"1stFlrSF\", \"TotRmsAbvGrd\", \"YearBuilt\", \"LotFrontage\"]\n",
    "        \n",
    "        self.cargar_datos()\n",
    "    \n",
    "    def cargar_datos(self):\n",
    "        \"\"\"\n",
    "        Carga los datos desde un archivo .npy, los convierte en un DataFrame de Pandas,\n",
    "        y mezcla aleatoriamente las filas con una semilla fija para asegurar consistencia.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.datos = np.load(self.ruta_archivo, allow_pickle=True)\n",
    "            self.df = pd.DataFrame(self.datos, columns=self.nombres_columnas)\n",
    "\n",
    "            # Mezclar las filas del DataFrame de forma reproducible\n",
    "            self.df = self.df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "            # Tratar valores faltantes en LotFrontage\n",
    "            if \"LotFrontage\" in self.df.columns:\n",
    "                mediana = self.df[\"LotFrontage\"].median()\n",
    "                self.df[\"LotFrontage\"].fillna(mediana, inplace=True)\n",
    "\n",
    "            print(\"Datos cargados y mezclados correctamente.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error al cargar los datos: {e}\")\n",
    "\n",
    "\n",
    "    def dividir_datos(self, proporcion_entrenamiento=0.8):\n",
    "        \"\"\"\n",
    "        Divide los datos mezclados en entrenamiento y validación.\n",
    "\n",
    "        Parámetros:\n",
    "        proporcion_entrenamiento (float): Proporción de los datos a utilizar para entrenamiento. \n",
    "                                        Por defecto es 0.8 (80%).\n",
    "        \"\"\"\n",
    "        tamano_entrenamiento = int(len(self.df) * proporcion_entrenamiento)\n",
    "        self.entrenamiento = self.df.iloc[:tamano_entrenamiento, :].copy()\n",
    "        self.validacion = self.df.iloc[tamano_entrenamiento:, :].copy()\n",
    "        print(f\"Datos divididos en {tamano_entrenamiento} registros para entrenamiento y {len(self.df) - tamano_entrenamiento} para validación.\")\n",
    "\n",
    "\n",
    "    def calcular_estadisticas(self):\n",
    "        \"\"\"\n",
    "        Calcula estadísticas descriptivas sobre los datos de entrenamiento.\n",
    "\n",
    "        Retorna:\n",
    "        pd.DataFrame: Un DataFrame con las estadísticas de cada columna, incluyendo:\n",
    "                      - Media\n",
    "                      - Máximo\n",
    "                      - Mínimo\n",
    "                      - Rango (peak-to-peak)\n",
    "                      - Desviación estándar\n",
    "        \"\"\"\n",
    "        if self.entrenamiento is None:\n",
    "            print(\"Primero ejecuta dividir_datos() antes de calcular estadísticas.\")\n",
    "            return None\n",
    "        \n",
    "        estadisticas = {\n",
    "            \"Media\": np.mean(self.entrenamiento, axis=0),\n",
    "            \"Maximo\": np.max(self.entrenamiento, axis=0),\n",
    "            \"Minimo\": np.min(self.entrenamiento, axis=0),\n",
    "            \"Rango\": np.ptp(self.entrenamiento, axis=0),  # Peak-to-peak (max - min)\n",
    "            \"DesviacionEstandar\": np.std(self.entrenamiento, axis=0)\n",
    "        }\n",
    "        \n",
    "        df_estadisticas = pd.DataFrame(estadisticas, index=self.nombres_columnas)\n",
    "        return df_estadisticas\n",
    "    \n",
    "    def mostrar_cabecera(self, n=5):\n",
    "        \"\"\"\n",
    "        Muestra las primeras 'n' filas del DataFrame.\n",
    "\n",
    "        Parámetros:\n",
    "        n (int): Número de filas a mostrar. Por defecto es 5.\n",
    "        \"\"\"\n",
    "        print(self.df.head(n))\n",
    "\n",
    "    def graficar_histogramas(self):\n",
    "        \"\"\"\n",
    "        Genera histogramas para cada variable en el dataset, incluyendo:\n",
    "        - Media (línea roja)\n",
    "        - Mediana (línea azul)\n",
    "        - Desviación estándar (líneas verdes en ±1σ)\n",
    "        - Máximo y mínimo (marcadores)\n",
    "        \"\"\"\n",
    "        for columna in self.nombres_columnas:\n",
    "            datos = self.df[columna].dropna()  # Elimina valores nulos si los hay\n",
    "\n",
    "            # Calcular estadísticas\n",
    "            media = np.mean(datos)\n",
    "            mediana = np.median(datos)\n",
    "            desviacion = np.std(datos)\n",
    "            minimo = np.min(datos)\n",
    "            maximo = np.max(datos)\n",
    "\n",
    "            # Crear histograma con seaborn\n",
    "            plt.figure(figsize=(8, 5))\n",
    "            sns.histplot(datos, kde=True, bins=30, color='lightseagreen')\n",
    "            #lightseagreen, turquoise\n",
    "\n",
    "            # Agregar líneas de estadísticas\n",
    "            plt.axvline(media, color='red', linestyle='dashed', linewidth=2, label=f'Media: {media:.2f}')\n",
    "            plt.axvline(mediana, color='blue', linestyle='dashed', linewidth=2, label=f'Mediana: {mediana:.2f}')\n",
    "            plt.axvline(media - desviacion, color='red', linestyle='dotted', linewidth=2, label=f'-1σ: {(media - desviacion):.2f}')\n",
    "            plt.axvline(media + desviacion, color='orange', linestyle='dotted', linewidth=2, label=f'+1σ: {(media + desviacion):.2f}')\n",
    "\n",
    "            # Marcar mínimo y máximo\n",
    "            plt.scatter([minimo, maximo], [0, 0], color='black', zorder=3, label=f'Mín: {minimo:.2f}, Máx: {maximo:.2f}')\n",
    "\n",
    "            # Configuración del gráfico\n",
    "            plt.title(f\"Histograma de {columna}\")\n",
    "            plt.xlabel(columna)\n",
    "            plt.ylabel(\"Frecuencia\")\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.show()\n",
    "\n",
    "    def analizar_correlaciones(self):\n",
    "        \"\"\"\n",
    "        Calcula y grafica la correlación entre cada variable independiente y la variable dependiente 'SalePrice'.\n",
    "        Muestra un scatterplot por variable con su coeficiente de correlación en el título.\n",
    "        Al final imprime las 2 variables con mayor correlación con 'SalePrice'.\n",
    "        \"\"\"\n",
    "        if self.df is None:\n",
    "            print(\"No hay datos cargados.\")\n",
    "            return\n",
    "\n",
    "        variable_objetivo = \"SalePrice\"\n",
    "        variables_independientes = [col for col in self.nombres_columnas if col != variable_objetivo]\n",
    "        correlaciones = {}\n",
    "\n",
    "        for variable in variables_independientes:\n",
    "            x = self.df[variable]\n",
    "            y = self.df[variable_objetivo]\n",
    "\n",
    "            # Calcular correlación\n",
    "            coef = np.corrcoef(x, y)[0, 1]\n",
    "            correlaciones[variable] = coef\n",
    "\n",
    "            # Graficar\n",
    "            plt.figure(figsize=(7, 5))\n",
    "            plt.scatter(x, y, alpha=0.6)\n",
    "            plt.title(f\"{variable} vs {variable_objetivo} (Correlación: {coef:.4f})\")\n",
    "            plt.xlabel(variable)\n",
    "            plt.ylabel(variable_objetivo)\n",
    "            plt.grid(True)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "        # Ordenar correlaciones absolutas de mayor a menor\n",
    "        correlaciones_ordenadas = sorted(correlaciones.items(), key=lambda item: abs(item[1]), reverse=True)\n",
    "\n",
    "        print(\"Variables con mayor correlación con SalePrice:\")\n",
    "        for variable, coef in correlaciones_ordenadas[:2]:\n",
    "            print(f\"{variable}: {coef:.4f}\")\n",
    "            \n",
    "    def graficar_matriz_correlacion_personalizada(self):\n",
    "        \"\"\"\n",
    "        Genera una matriz de correlación personalizada:\n",
    "        - Parte inferior: scatterplots.\n",
    "        - Parte superior: coeficiente de correlación (Pearson).\n",
    "        - Solo se usan seaborn, matplotlib, numpy, pandas.\n",
    "        \"\"\"\n",
    "        # Definir dimensiones\n",
    "        columnas = self.df.columns\n",
    "        num_vars = len(columnas)\n",
    "\n",
    "        # Crear PairGrid\n",
    "        grid = sns.PairGrid(self.df, vars=columnas, diag_sharey=False)\n",
    "\n",
    "        # Parte inferior: scatterplot\n",
    "        grid.map_lower(sns.scatterplot, s=10, alpha=0.6)\n",
    "\n",
    "        # Parte superior: texto con coeficiente de correlación\n",
    "        def correlacion(x, y, **kwargs):\n",
    "            r = np.corrcoef(x, y)[0, 1]\n",
    "            ax = plt.gca()\n",
    "            ax.annotate(f\"{r:.2f}\", xy=(0.5, 0.5), xycoords=ax.transAxes,\n",
    "                        ha='center', va='center', fontsize=12)\n",
    "\n",
    "        grid.map_upper(correlacion)\n",
    "\n",
    "        # Diagonal: histogramas\n",
    "        grid.map_diag(sns.histplot, kde=True)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    def entrenar_modelo_lineal_simple(self, x, y, epochs, imprimir_error_cada, alpha):\n",
    "        \"\"\"\n",
    "        Entrena un modelo de regresión lineal simple y = β0 + β1 * x utilizando descenso por gradiente.\n",
    "\n",
    "        Parámetros:\n",
    "        x (np.ndarray): Variable independiente (6.1)\n",
    "        y (np.ndarray): Variable dependiente (6.2)\n",
    "        epochs (int): Número de iteraciones de entrenamiento (6.3)\n",
    "        imprimir_error_cada (int): Frecuencia de impresión del error (6.4)\n",
    "        alpha (float): Tasa de aprendizaje (6.5)\n",
    "\n",
    "        Retorna:\n",
    "        tuple: β0 (intercepto), β1 (pendiente)\n",
    "        \"\"\"\n",
    "        n = len(x)\n",
    "\n",
    "        # Inicialización de parámetros\n",
    "        beta_0 = 0\n",
    "        beta_1 = 0\n",
    "\n",
    "        for epoch in range(1, epochs + 1):\n",
    "\n",
    "            # 6.1 y 6.2: cálculo de predicciones usando x e y\n",
    "            y_pred = beta_0 + beta_1 * x\n",
    "\n",
    "            # Cálculo del error\n",
    "            error = y - y_pred\n",
    "\n",
    "            # Gradientes para descenso por gradiente\n",
    "            grad_b0 = (-2 / n) * np.sum(error)\n",
    "            grad_b1 = (-2 / n) * np.sum(error * x)\n",
    "\n",
    "            # 6.5: actualización de parámetros usando alpha\n",
    "            beta_0 -= alpha * grad_b0\n",
    "            beta_1 -= alpha * grad_b1\n",
    "\n",
    "            # 6.4: imprimir error cada cierto número de iteraciones\n",
    "            if epoch % imprimir_error_cada == 0:\n",
    "                mse = np.mean(error**2)\n",
    "                print(f\"Iteración {epoch} - Error (RMSE): {np.sqrt(mse):.4f}, beta_0: {(beta_0):.4f}, beta_1: {(beta_1):.4f}  \")\n",
    "\n",
    "        return beta_0, beta_1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos cargados y mezclados correctamente.\n",
      "   SalePrice  OverallQual  1stFlrSF  TotRmsAbvGrd  YearBuilt  LotFrontage\n",
      "0   154500.0          6.0    1068.0           6.0     1963.0         70.0\n",
      "1   325000.0          8.0    1500.0           9.0     1994.0         98.0\n",
      "2   115000.0          5.0    1028.0           5.0     1927.0         56.0\n",
      "3   159000.0          6.0    1004.0           7.0     1947.0         50.0\n",
      "4   315500.0          9.0    1620.0           6.0     2007.0         89.0\n",
      "5    75500.0          4.0     630.0           3.0     1972.0         21.0\n",
      "6   311500.0          7.0    1137.0           8.0     1939.0         69.0\n",
      "7   146000.0          6.0     855.0           7.0     1978.0         24.0\n",
      "8    84500.0          4.0     630.0           3.0     1970.0         21.0\n",
      "9   135500.0          5.0     872.0           8.0     1955.0         59.0\n",
      "Datos divididos en 1168 registros para entrenamiento y 292 para validación.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EC\\AppData\\Local\\Temp\\ipykernel_16108\\70130815.py:45: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  self.df[\"LotFrontage\"].fillna(mediana, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# ---------- DEFINICION Y USO DE LA CLASE ----------\n",
    "if __name__ == \"__main__\":\n",
    "    # Crear una instancia de la clase\n",
    "    ruta_archivo = r\"C:\\PythonWs\\Proyecto\\proyecto_training_data.npy\"\n",
    "    analizador = AnalizadorDatos(ruta_archivo)\n",
    "\n",
    "    # Mostrar las primeras filas\n",
    "    analizador.mostrar_cabecera(10)\n",
    "\n",
    "    # Separar los datos en entrenamiento y validación\n",
    "    analizador.dividir_datos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      Media    Maximo   Minimo     Rango  DesviacionEstandar\n",
      "SalePrice     181081.876712  755000.0  34900.0  720100.0        81096.489736\n",
      "OverallQual        6.095034      10.0      1.0       9.0            1.402802\n",
      "1stFlrSF        1161.268836    4692.0    334.0    4358.0          393.372616\n",
      "TotRmsAbvGrd       6.532534      14.0      2.0      12.0            1.626715\n",
      "YearBuilt       1971.120719    2009.0   1872.0     137.0           30.266595\n",
      "LotFrontage       70.049658     313.0     21.0     292.0           22.723041\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Calcular y mostrar estadísticas descriptivas\n",
    "estadisticas = analizador.calcular_estadisticas()\n",
    "print(estadisticas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analizador.graficar_histogramas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Para cada variable independiente x :\n",
    "analizador.analizar_correlaciones()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si ya tienes tu dataframe dentro de la clase, fuera puedes hacer:\n",
    "analizador.graficar_matriz_correlacion_personalizada()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables seleccionadas \n",
    "# Variable dependiente = SalePrice\n",
    "# Variable independiente 1 = OverallQual: (Coeficiente de correlacion 0.7910) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteración 100 - Error (RMSE): 101846.1305, beta_0: 2466.6530, beta_1: 16474.3968  \n",
      "Iteración 200 - Error (RMSE): 66732.9900, beta_0: 3514.1539, beta_1: 23851.6069  \n",
      "Iteración 300 - Error (RMSE): 57168.9531, beta_0: 3926.9647, beta_1: 27159.9057  \n",
      "Iteración 400 - Error (RMSE): 55049.0398, beta_0: 4055.9520, beta_1: 28648.2921  \n",
      "Iteración 500 - Error (RMSE): 54607.4743, beta_0: 4058.0482, beta_1: 29322.6769  \n",
      "Iteración 600 - Error (RMSE): 54511.1123, beta_0: 4003.4443, beta_1: 29632.9744  \n",
      "Iteración 700 - Error (RMSE): 54484.2285, beta_0: 3923.5346, beta_1: 29780.4178  \n",
      "Iteración 800 - Error (RMSE): 54471.2758, beta_0: 3832.3609, beta_1: 29855.0129  \n",
      "Iteración 900 - Error (RMSE): 54461.1247, beta_0: 3736.2035, beta_1: 29897.0166  \n",
      "Iteración 1000 - Error (RMSE): 54451.5478, beta_0: 3637.8714, beta_1: 29924.4347  \n",
      "Modelo entrenado: y = 3637.87 + 29924.43 * x\n"
     ]
    }
   ],
   "source": [
    "#6.1 Vector con la variable independiente x,\n",
    "x = analizador.entrenamiento[\"OverallQual\"].to_numpy()\n",
    "\n",
    "#6.2 Vector con la variable dependiente y,\n",
    "y = analizador.entrenamiento[\"SalePrice\"].to_numpy()\n",
    "\n",
    "beta_0, beta_1 = analizador.entrenar_modelo_lineal_simple(x, y, 1000, 100, 0.0001)\n",
    "print(f\"Modelo entrenado: y = {beta_0:.2f} + {beta_1:.2f} * x\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
